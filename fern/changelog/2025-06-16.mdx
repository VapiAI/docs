# New Model Selection, Enhanced Edge Conditions, Simplified Credentials, and More

1. **New Model Selection in Workflows**: You can now specify the AI model used in workflows by setting the `model` property in workflow schemas. This allows choosing between OpenAI, Anthropic, Google, or custom models to better suit application requirements.

2. **Enhanced Workflow Edge Conditions**: Workflows now support [`Logic Edge Conditions`](https://api.vapi.ai/api#:~:text=LogicEdgeCondition) and [`Failed Edge Conditions`](https://api.vapi.ai/api#:~:text=FailedEdgeCondition) for edges. Specify logic edge conditions with [Liquid JS templates](https://liquidjs.com/) to enable more complex logic and error handling within workflows, allowing for dynamic and responsive workflow designs.

3. **Simplified Credential Configuration**: Your uploaded credentials are now automatically configured with the correct fallback index, simplifying the setup process with cloud providers.

4. **Updated End Reasons for ElevenLabs**: The following `endedReason` values been removed from `Call`:
   - `pipeline-error-eleven-labs-503-server-error`
   - `call.in-progress.error-providerfault-eleven-labs-503-server-error`

   You should update your error handling code to reflect the current set of possible end reasons.

<Warning>
**Prompt Length Limitations**: The `globalPrompt` in workflows now has a maximum length of 5000 characters, and the `liquid` property in `LogicEdgeCondition` now has a maximum length of 1000 characters. Ensure prompts and conditions stay within these limits to prevent errors.
</Warning>
