---
title: Monitoring & Operating
subtitle: Visualize trends, track operational health, and ensure production reliability. This is the **MONITOR phase** of the [observability framework](/observability/framework).
slug: observability/monitoring
---

<span className="internal-note">This page is in Skeleton Draft stage - structure and scope for review, detailed content to be developed in iteration 2</span>

## What is monitoring and operating?

**Monitoring & Operating** means running your voice AI system in production with continuous visibility into its health and performance. This stage answers critical operational questions:

- How many calls are happening right now?
- What's my average call cost this week?
- Is my success rate dropping?
- Are any assistants experiencing unusual error rates?
- When should I be alerted about problems?

**Operating a voice AI system** requires more than traditional software monitoring. Voice AI systems have unique operational characteristics:

- **Real-time performance matters** — Latency, interruption handling, and voice quality directly impact user experience
- **Cost scales with usage** — Every call has LLM, TTS, and STT costs that must be tracked
- **Quality is subjective** — Success isn't just "200 OK" - it's whether the conversation achieved its goal
- **Failures are multi-layered** — Issues can occur in the LLM, voice pipeline, tool execution, or external integrations

**The goal**: Catch problems early (before customers complain), understand operational patterns, and maintain production reliability.

---

## Monitoring & Operating tools at a glance

| Tool | What it does | Best for |
|------|--------------|----------|
| **Boards** | Drag-and-drop visual dashboards with charts, metrics, and global filters. Queries scalar Structured Output fields. | Real-time operational visibility, team dashboards, custom reporting |
| **Insights API** | [TBD: Programmatic querying and alerting capabilities?] | [TBD: Automated alerts, custom monitoring logic?] |
| **Analytics API** | [TBD: Aggregated operational metrics?] | [TBD: Cost tracking, performance monitoring?] |
| **Langfuse Integration** | Real-time observability platform integration for call monitoring and tracing | End-to-end observability, LLM performance tracking, distributed tracing |
| **Webhook-to-External** | Export call data to third-party monitoring platforms (Datadog, Braintrust, Grafana, custom dashboards) | Enterprise monitoring stacks, unified observability across systems, custom alerting |

<span className="vapi-validation">Confirm this list of monitoring tools is complete and accurate. Need clarification on: What are the key capabilities and use cases for Insights API vs Analytics API? How do they differ? When should users choose one over the other? What monitoring capabilities does Langfuse provide beyond basic call data? Are there other built-in or recommended monitoring integrations? What's the roadmap for built-in alerting capabilities?</span>

---

## Boards

**[Placeholder - Full detail section]**

→ **[Build your first dashboard in Boards quickstart](/observability/boards-quickstart)**

---

## Analytics API

**[Placeholder - Full detail section]**

<span className="internal-note">What's the difference between Analytics API and Insights API? What are Analytics API's key capabilities? When should users choose Analytics API vs Insights API vs Boards?</span>

---

## Insights API

**[Placeholder - Full detail section]**

<Warning>
  **Insights API is currently undocumented**. If you need flexible querying or programmatic alerting, contact Vapi support for guidance.
</Warning>

<span className="internal-note">Should Insights API be formally documented? What's the relationship between Insights API and Analytics API? Is Insights API the primary alerting mechanism, or are built-in alerts planned?</span>

---

## Langfuse Integration

**[Placeholder - Full detail section]**

<span className="vapi-validation">What are Langfuse's key capabilities for Vapi users? Does it provide real-time alerting? What metrics/traces does it capture? Are there setup requirements or limitations?</span>

---

## Webhook-to-External Monitoring

**[Placeholder - Full detail section]**

<span className="vapi-validation">What are recommended third-party monitoring platforms for Vapi (Datadog, Braintrust, etc.)? Are there integration guides or examples? What webhook events are most useful for monitoring?</span>

---

## Alerting Strategies

**[Placeholder - Full detail section]**

<span className="internal-note">Are built-in alerts on the roadmap?</span>

---

## Monitoring Best Practices

**[Placeholder - Full detail section]**

Topics to cover:
- Define baseline metrics
- Set alert thresholds (critical, warning, informational)
- Monitor continuously, not reactively
- Create role-specific dashboards

---

## What you'll learn in detailed guides

- [Boards quickstart](/observability/boards-quickstart) — Create custom dashboards in minutes
- (Planned) Langfuse integration guide — Set up real-time observability
- (Planned) Webhook monitoring guide — Export to external platforms
- (Planned) Analytics API reference — Programmatic monitoring

---

## Key takeaway

**Monitor continuously**. Production issues caught early (via dashboards or alerts) are easier to fix than issues discovered through customer complaints.

Operating a voice AI system requires proactive monitoring. Set up visibility on day one of production launch.

---

## Next steps

<CardGroup cols={2}>
  <Card
    title="Boards quickstart"
    icon="chart-line"
    href="/observability/boards-quickstart"
  >
    Build your first monitoring dashboard
  </Card>

  <Card
    title="Optimization workflows"
    icon="arrow-trend-up"
    href="/observability/optimization-workflows"
  >
    Next stage: Use monitoring data to improve
  </Card>

  <Card
    title="Back to overview"
    icon="arrow-left"
    href="/observability/framework"
  >
    Return to observability framework
  </Card>
</CardGroup>
